# High Availability and Fault Tolerance in AWS

## Achieving High Availability and Fault Tolerance

In AWS, to achieve high availability (HA) and fault tolerance (FT) for an application, we need to use a combination of services that ensure traffic is evenly distributed, and faulty instances are automatically replaced.

While the Elastic Load Balancer (ELB) routes traffic to healthy servers based on health checks, it does **NOT** recreate servers if they fail. Instead, ELB simply stops sending traffic to unhealthy instances.

To automatically recreate instances when they fail, we use **Auto Scaling** combined with ELB.

---

## What is Auto Scaling?

**Auto Scaling** is an AWS service that automatically adjusts the number of EC2 instances in response to changing demand. It ensures that the application always has the right number of instances to handle the load.

### Benefits of Auto Scaling:

1. **High Availability:** Automatically replaces unhealthy instances and distributes instances across multiple Availability Zones.
2. **Fault Tolerance:** Detects and replaces failed instances to maintain application availability.
3. **Scalability:** Dynamically increases or decreases the number of instances based on demand.
4. **Cost Optimization:** Ensures you only run as many instances as needed, reducing costs during low-traffic periods.
5. **Elasticity:** Quickly adapts to spikes in traffic without manual intervention.

---

## Components of Auto Scaling

To implement auto scaling, the following components are required:

### 1. **Auto Scaling Group (ASG):**
- A logical group of EC2 instances managed by Auto Scaling.
- Defines the **minimum**, **maximum**, and **desired** number of instances.
- Automatically launches or terminates instances based on scaling policies.

**Key Configurations:**
- **Minimum Capacity:** The least number of instances the ASG should maintain at all times.
- **Maximum Capacity:** The most number of instances the ASG can scale up to.
- **Desired Capacity:** The number of instances the ASG tries to maintain (can dynamically adjust based on scaling policies).
- **Availability Zones:** Ensures instances are spread across multiple AZs for high availability.

### 2. **Launch Template or Launch Configuration:**
- Specifies how new EC2 instances are created.
- Includes details like:
  - AMI (Amazon Machine Image)
  - Instance type (e.g., t2.micro, m5.large)
  - Security groups
  - Key pairs for SSH
  - User data scripts (for initializing the instance)
- **Launch Templates** are the recommended way, offering versioning and more flexibility compared to **Launch Configurations**.

### 3. **Scaling Policies:**
- Rules that define when and how to scale the instances.
- **Types of Scaling Policies:**
  - **Target Tracking Scaling:** Adjusts instance count to maintain a metric target (e.g., keeping CPU utilization at 50%).
  - **Step Scaling:** Adds or removes instances in steps based on metric thresholds.
  - **Scheduled Scaling:** Scales at pre-defined times (e.g., adding instances every morning at 9 AM).

### 4. **CloudWatch Alarms:**
- **Amazon CloudWatch** monitors metrics and triggers scaling actions via alarms.
- An alarm watches a single metric (like CPU utilization, memory usage, or request count) and performs actions when the value exceeds or falls below a threshold.
- For example:
  - **Scale Out:** Add instances when CPU utilization exceeds 70%.
  - **Scale In:** Remove instances when CPU utilization drops below 30%.
- These alarms are linked to scaling policies to control how Auto Scaling responds to changing conditions.

### 5. **Health Checks:**
- Auto Scaling performs health checks to identify and replace unhealthy instances.
- Types of health checks:
  - **EC2 Health Checks:** Verifies if the instance is running.
  - **ELB Health Checks:** Ensures instances registered with the load balancer are healthy.

### 6. **Elastic Load Balancer (ELB):**
- Distributes incoming traffic across healthy instances.
- Works with ASG by automatically registering new instances and removing terminated ones.
- Ensures zero-downtime scaling.

---

## Example: Auto Scaling with ELB and CloudWatch Alarms

Let’s walk through an example to better understand how these components work together.

### Scenario:
You have a web application running on EC2 instances. You want to:
- Maintain a minimum of 2 instances.
- Allow scaling up to a maximum of 6 instances.
- Start with a desired capacity of 3 instances.
- Add an instance if CPU usage exceeds 70% for 5 minutes.
- Remove an instance if CPU usage falls below 30% for 5 minutes.

### Steps:
1. **Create a Launch Template:** Define the AMI, instance type, and security groups.
2. **Configure an Auto Scaling Group (ASG):**
   - Minimum capacity: 2
   - Maximum capacity: 6
   - Desired capacity: 3
   - Attach the Launch Template
3. **Set up CloudWatch Alarms:**
   - **High CPU Alarm:** Triggers a scale-out action when CPU > 70%.
   - **Low CPU Alarm:** Triggers a scale-in action when CPU < 30%.
4. **Define Scaling Policies:**
   - Scale out: Add 1 instance when High CPU Alarm triggers.
   - Scale in: Remove 1 instance when Low CPU Alarm triggers.
5. **Attach the ASG to an ELB:** Ensure incoming traffic is distributed evenly across healthy instances.

### Flow:
- When CPU exceeds 70%, CloudWatch triggers the High CPU Alarm.
- The ASG adds an instance according to the scaling policy.
- ELB automatically registers the new instance and routes traffic to it.
- If CPU drops below 30%, CloudWatch triggers the Low CPU Alarm.
- The ASG terminates an instance, and ELB removes it from its target group.

---

## How Auto Scaling, ELB, and CloudWatch Work Together

1. **Traffic Routing:** ELB distributes traffic to instances in an ASG.
2. **Health Monitoring:** ELB checks instance health and stops routing to unhealthy ones.
3. **CloudWatch Monitoring:** Monitors CPU, memory, and other metrics.
4. **Alarms and Scaling:** CloudWatch Alarms trigger scaling actions based on thresholds.
5. **Instance Replacement:** ASG launches or terminates instances based on scaling policies.
6. **Dynamic Scaling:** The number of instances automatically adjusts, ensuring optimal performance and cost.

---

By combining **Auto Scaling Groups (ASG)**, **Elastic Load Balancers (ELB)**, and **CloudWatch Alarms**, we can achieve high availability, fault tolerance, and dynamic scalability for our applications in AWS.

---
---
---

# AWS Auto Scaling Group (ASG) Notes

## Understanding Auto Scaling Group (ASG) Capacity

### ASG Capacity Parameters:
- **Minimum capacity:** 2 → The ASG will **never** scale below 2 instances.
- **Maximum capacity:** 6 → The ASG will **never** scale above 6 instances.
- **Desired capacity:** 3 → The ASG **tries to maintain** 3 instances under normal conditions.

### Clarification on Desired vs. Min/Max Capacity
- The **desired capacity (3)** is the **target** number of instances ASG aims to keep running.
- The **minimum capacity (2)** is the **lowest possible** instance count allowed.
- The **maximum capacity (6)** is the **highest possible** instance count allowed.
- **There is no conflict** between `min=2` and `desired=3` because the desired count is within the min-max range.

## How ASG Works in Different Scenarios

### **1. Without Scaling Policies** (Static Scaling)
- ASG will **always maintain** 3 instances (as per desired capacity).
- Even if the load is low, ASG **won’t scale down** to 2 instances.
- Even if the load is high, ASG **won’t scale up** beyond 3 instances.
- The only way to change instance count is **manual intervention** (e.g., updating desired capacity).

#### **Example (Without Scaling Policies)**
- You configure ASG: `min=2, max=6, desired=3`.
- Current load: **Low**, but ASG still maintains **3 instances**.
- Current load: **High**, but ASG won’t increase beyond **3 instances**.
- Only way to change instance count: **Manually updating desired capacity.**

### **2. With Scaling Policies** (Dynamic Scaling)
- ASG automatically **adjusts instances** based on demand.
- It will scale **between the min (2) and max (6)** dynamically.
- If demand **decreases**, ASG **can reduce** instances (but never below 2).
- If demand **increases**, ASG **can add** instances (but never above 6).

#### **Example (With Scaling Policies)**
- You configure ASG: `min=2, max=6, desired=3`.
- Scaling policy: **Scale up** if CPU > 70%, **Scale down** if CPU < 30%.

**Scenario 1: High Load**
- CPU usage reaches **80%** → ASG **adds instances** (e.g., 4, 5, or up to max 6).

**Scenario 2: Low Load**
- CPU usage drops to **20%** → ASG **removes instances** (down to minimum 2).

## Best Practices for Selecting Min, Max, and Desired Instances

### **1. Minimum Instances** (Base Load Handling)
- Set this based on the **minimum traffic** your application gets, even during off-peak hours.
- Ensure at least **two instances** for **high availability and redundancy** (to prevent single points of failure).
- Example: If your application can run on 1 instance but needs redundancy, set `min=2`.

### **2. Maximum Instances** (Peak Load Handling)
- This should be based on the **maximum expected traffic**.
- Consider the highest number of instances needed to handle **spikes in demand**.
- Example: If peak load requires 6 instances, set `max=6`.

### **3. Desired Instances** (Normal Load Handling)
- This should reflect your **typical** usage pattern under normal conditions.
- Based on **average traffic patterns**, determine how many instances are usually needed.
- Example: If your app generally requires 3 instances, set `desired=3`.

### **4. Scaling Policies for Efficiency**
- Use CPU/memory-based auto-scaling policies to adjust instances dynamically.
- Example: Scale up when **CPU > 70%**, scale down when **CPU < 30%**.
- Always ensure your scaling range allows room for **growth and contraction**.

### **Summary of Selection Approach**
| Setting  | Purpose |
|----------|----------|
| **Min**  | Ensures base availability, set to cover **low traffic periods** |
| **Max**  | Defines the upper limit, set to cover **peak loads** |
| **Desired** | The default number of instances for **normal operations** |
| **Scaling Policies** | Adjust dynamically to optimize performance and cost |

By following this approach, you can balance **cost efficiency** and **performance** while ensuring your application scales effectively under different loads.

This note summarizes how Auto Scaling Groups (ASG) behave under different conditions and clarifies the role of min, max, and desired capacities.

---
---
---

# Setting Up Auto Scaling for Applications on EC2 Using AMI

## 1. Overview

This guide explains how to set up auto scaling for an application running on EC2 instances. The setup includes:

- **Creating an AMI** (Amazon Machine Image)
- **Configuring a Launch Template**
- **Creating an Auto Scaling Group (ASG)**
- **Integrating with a Load Balancer**
- **Setting up auto scaling policies**

The goal is to automatically replace failed instances and dynamically scale the number of instances based on load.

---

## 2. Steps to Set Up Auto Scaling

### Step 1: Create an AMI

An AMI is a pre-configured image that contains the OS, application code, and dependencies.

#### Create an AMI from an existing EC2 instance:

1. Go to the EC2 dashboard.
2. Select the running instance with your application.
3. Click **Actions > Image and templates > Create Image**.
4. Provide:
   - **Image name**: `app-ami`
   - **Instance storage**: Keep default (8GB or customize as needed)
5. Click **Create Image**.

The AMI will be available in the **AMIs** section once it is created.

---

### Step 2: Create a Launch Template

A launch template specifies the configuration for new instances, including the AMI, instance type, key pair, and user data.

#### Steps to create a launch template:

1. Go to the EC2 dashboard.
2. Navigate to **Launch Templates** and click **Create Launch Template**.
3. Provide the following details:
   - **Launch template name**: `app-launch-template`
   - **AMI**: Select the AMI created (`app-ami`)
   - **Instance type**: `t2.micro`
   - **Key pair**: `dev-kp`
   - **Security groups**: Select existing security group `app-sg`
   - **Storage**: 8GB (default or customize as needed)
   - **User data**: Add startup commands if needed:

```bash
#!/bin/bash
cd /home/ec2-user/app
nohup ./start.sh &
```

4. Click **Create Launch Template**.

---

### Step 3: Create an Auto Scaling Group (ASG)

The Auto Scaling Group manages scaling operations by launching new instances based on the launch template.

#### Steps to create an Auto Scaling Group:

1. Go to the **Auto Scaling Groups** page.
2. Click **Create Auto Scaling Group**.
3. Configure the group:
   - **Auto Scaling Group Name**: `app-asg`
   - **Launch Template**: Select `app-launch-template`
   - **Version**: Latest (1)
4. **Networking**:
   - Select **Availability Zones and Subnets** where the instances should be launched.
5. **Load Balancer**:
   - Attach to an existing load balancer.
   - Select **Existing Target Groups** and choose the target group where your current EC2 instances are registered.
6. **Health Checks**:
   - Turn on **Elastic Load Balancing (ELB) health checks**.
   - Turn on **Amazon EBS health checks**.
   - **Health check grace period**: 100 seconds.

---

### Step 4: Configure Scaling Policies

Set the group size and scaling policies.

#### Group size:

- **Desired capacity**: 3
- **Min size**: 2
- **Max size**: 5

#### Scaling policy:

1. Choose **Target Tracking Scaling Policy**.
2. **Metric type**: Average CPU utilization.
3. **Target value**: 50%.
4. **Instance warmup period**: 100 seconds (to give new instances time to fully start).

#### Scaling cooldown period:

- Set the cooldown period for scale-in actions to 5 minutes to ensure quick but stable scale-in events.

Click **Create Auto Scaling Group**.

---

## 3. Testing and Validation

### Validate auto scaling:

1. **Failure test**:
   - Manually terminate an instance.
   - The ASG should automatically launch a replacement.
2. **Load test**:
   - Use a tool like Apache Bench (ab) to simulate high traffic:

```bash
ab -n 1000 -c 100 http://<load-balancer-dns-name>/
```

- Alternatively, use the `stress-ng` tool to artificially increase CPU load:

```bash
# Install stress-ng if not already installed
sudo yum install stress-ng -y

# Stress test CPU: 4 workers for 1000 seconds
stress-ng --cpu 4 --cpu-load 80 --timeout 1000s
```

- The ASG should add instances if CPU crosses 50%.

### Verify load balancer integration:

- Access your app through the load balancer:

```
http://<load-balancer-dns-name>/
http://<load-balancer-dns-name>/health
```

Ensure requests are distributed evenly across instances.

---

## 4. Clean Up (Optional)

To delete resources:

```bash
aws autoscaling delete-auto-scaling-group --auto-scaling-group-name app-asg --force-delete
aws ec2 delete-launch-template --launch-template-name app-launch-template
```

Remove the AMI if no longer needed:

```bash
aws ec2 deregister-image --image-id ami-xxxxxxxxxxxxxxxxx
```

---

## 5. Conclusion

By using AMIs, launch templates, and auto scaling groups, we achieve:

- Automatic replacement of failed instances.
- Dynamic scaling based on CPU utilization.
- Seamless traffic distribution with load balancers.

This setup ensures high availability and responsiveness for your application.

---

