# Load Balancer and Regions vs Availability Zones (AZs)

## Region
A **Region** is a large geographical area containing multiple data centers. Example: `us-east-1`.

## Availability Zones (AZs)
**Availability Zones (AZs)** are separate, isolated data centers within a Region. Example: `us-east-1a`, `us-east-1b`, `us-east-1c`.

## Load Balancer Behavior
When using a **Load Balancer** in AWS:

- It can **distribute traffic across EC2 instances** located in **different AZs**.
- This **ensures high availability and fault tolerance** because if one AZ fails, traffic can be routed to instances in other AZs.
- **All AZs must be within the same Region** (e.g., `us-east-1`).
- **A Load Balancer cannot balance traffic across different Regions** (e.g., between `us-east-1` and `us-west-1`).

## Example
1. Launch EC2 instances in the following AZs within the same Region `us-east-1`:
   - `us-east-1a`
   - `us-east-1b`
   - `us-east-1c`

2. Create a **Load Balancer** in the Region `us-east-1`.

3. The Load Balancer will **distribute incoming traffic** across EC2 instances in `us-east-1a`, `us-east-1b`, and `us-east-1c`.

4. **However, the Load Balancer will not route traffic to instances in another Region like `us-west-1`**.

This behavior is important to understand when designing for **high availability** and **disaster recovery** in AWS.

---

# Layers in Load Balancing
Load balancing can occur at different layers of the OSI model. The most common are:

## Layer 4 Load Balancing (Transport Layer)
- Operates at the **Transport Layer (TCP/UDP)**.
- Makes routing decisions based on **IP addresses and ports**.
- Does **not inspect application content**.
- Faster because it works with lower-level network information.
- Examples: **AWS Network Load Balancer (NLB)**, **HAProxy (TCP mode)**.

## Layer 7 Load Balancing (Application Layer)
- Operates at the **Application Layer (HTTP/HTTPS)**.
- Understands application-level protocols like **HTTP**.
- Can make routing decisions based on **URLs, headers, cookies, or request content**.
- Supports **advanced traffic routing** such as path-based and host-based routing.
- Examples: **AWS Application Load Balancer (ALB)**, **NGINX (HTTP mode)**, **Apache HTTP Server**.

## Key Differences Between Layer 4 and Layer 7 Load Balancing
| Feature                    | Layer 4 (Transport Layer) | Layer 7 (Application Layer) |
|-----------------------------|-----------------------------|------------------------------|
| Protocol Level              | TCP/UDP                    | HTTP/HTTPS                   |
| Traffic Inspection          | No                         | Yes                          |
| Performance                 | High                       | Moderate                     |
| Routing Flexibility         | Basic                      | Advanced                     |
| Example Use Case            | Simple traffic forwarding  | Content-based routing        |

---

# OSI Model and its 7 Layers
The **OSI (Open Systems Interconnection) model** is a conceptual framework used to understand network communication. It has **7 layers**, each with a specific role:

| Layer Number | Layer Name         | Description                                      |
|--------------|---------------------|--------------------------------------------------|
| 7            | Application         | User interfaces and applications (HTTP, FTP)    |
| 6            | Presentation        | Data formatting, encryption, compression        |
| 5            | Session             | Manages sessions between devices                |
| 4            | Transport           | Reliable data delivery (TCP, UDP)               |
| 3            | Network             | Routing, IP addresses                           |
| 2            | Data Link           | MAC addresses, switches                         |
| 1            | Physical            | Physical hardware (cables, NICs)                |

---

# Web Servers and Application Servers
## Web Servers
Web servers handle HTTP requests from clients (e.g., browsers). They serve static content like HTML, CSS, and images. Popular web servers include:

- **Apache HTTP Server (httpd)**
- **NGINX**
- **HAProxy**

## Application Servers
Application servers handle dynamic content and business logic. They often run Java applications and interact with databases. Examples include:

- **Apache Tomcat**
- **JBoss (WildFly)**
- **Oracle WebLogic**
- **IBM WebSphere**

## Reverse Proxy with Web Servers
Web servers like **NGINX** can also act as a **reverse proxy**. This means they can:

- Receive client requests.
- Forward the requests to backend servers (e.g., application servers or multiple web servers).
- Balance the load between multiple backend servers.
- Return the response from backend servers to the client.

## Example: Load Balancing with NGINX
Assuming you have two web servers serving the same content:

| Server Name  | IP Address     |
| ------------ | -------------- |
| Web Server 1 | `172.31.22.151` |
| Web Server 2 | `172.31.22.152` |

### 1. Install NGINX
```bash
sudo apt update
sudo apt install nginx -y
sudo systemctl start nginx
sudo systemctl enable nginx
sudo systemctl stop nginx
```

### 2. [Configure NGINX as a Load Balancer](https://nginx.org/en/docs/http/load_balancing.html)
- [Refer Nginx Documentation here](https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/)

Edit the NGINX configuration file (e.g., `/etc/nginx/nginx.conf`):

```nginx
worker_processes auto;

events {
    worker_connections 1024;
}

http {
    upstream backend_servers {
        server 172.31.22.151;
        server 172.31.22.152;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://backend_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}
```

#### Explanation:

1Ô∏è‚É£ **worker_processes auto;**
üëâ Decides how many workers (helpers) Nginx should use. More workers = better handling of traffic.

2Ô∏è‚É£ **events { worker_connections 1024; }**
üëâ Each worker can handle up to 1,024 visitors at the same time.

3Ô∏è‚É£ **http {} (Main web settings)**

- **upstream backend_servers {}**
  - Defines a group of two servers (`172.31.22.152` & `172.31.17.27`).
  - Nginx will send traffic to them one by one (load balancing).

- **server { listen 80; }**
  - Listens for website visitors on port 80 (default web traffic port).

- **location / { proxy_pass http://backend_servers; }**
  - When someone visits your site, Nginx forwards the request to one of the backend servers.

- **proxy_set_header ...**
  - These lines help keep track of where the request came from.

#### Imagine This Scenario:
You have a call center where customers call a single phone number, but you have two customer service agents answering the calls.

- **Nginx is the receptionist üìû**
- Customers (website visitors) call the main number (visit your website).
- Two customer service agents (backend servers) answer the calls.
- The receptionist (Nginx) forwards each call to one of the agents to balance the workload.

### 3. Check the nginx configuration
```bash
sudo nginx -t
```

### 4. Restart NGINX
```bash
sudo systemctl restart nginx
```

### 5. How It Works
- When a client accesses the load balancer‚Äôs IP, NGINX will distribute the requests between `172.31.22.151` and `172.31.22.152`.
- If one server fails, traffic will continue to the remaining server.

This setup ensures availability and scalability.



---
---
---

# AWS Load Balancers

## Types of Load Balancers in AWS
AWS provides different types of load balancers to distribute incoming traffic across multiple targets. The main types are:

### 1. **Application Load Balancer (ALB)**
   - Operates at the **Layer 7 (Application Layer)** of the OSI model.
   - Supports **HTTP, HTTPS** protocols.
   - Best suited for applications that require **intelligent routing** based on request attributes like URL paths, host headers, etc.
   - Example Use Case: Routing requests to different microservices based on the path (e.g., `/api` requests go to one target group and `/user` requests go to another).

### 2. **Network Load Balancer (NLB)**
   - Operates at **Layer 4 (Transport Layer)**.
   - Supports **TCP, UDP, TLS** protocols.
   - Provides **low latency and high performance**, handling millions of requests per second.
   - Example Use Case: Load balancing TCP traffic for a real-time financial application.

### 3. **Gateway Load Balancer (GWLB)**
   - Works at **Layer 3 (Network Layer)**.
   - Primarily used for **inspecting traffic** and integrating with third-party security appliances.
   - Example Use Case: Distributing traffic to intrusion detection/prevention systems (IDS/IPS).

### 4. **Classic Load Balancer (CLB) [Legacy]**
   - Operates at **both Layer 4 (Transport) and Layer 7 (Application)**.
   - Supports **HTTP, HTTPS, TCP, and SSL**.
   - AWS recommends using ALB or NLB instead.
   - Example Use Case: Basic load balancing without advanced routing capabilities.

## Target Groups in AWS Load Balancer
A **target group** is a logical grouping of actual backend servers (EC2 instances, containers, Lambda functions, or IPs) behind a load balancer.
- When a request arrives, the load balancer forwards it to one of the targets in the associated target group.
- Each target group has its own **health check settings**.
- Target groups allow **fine-grained routing**, enabling different paths to be served by different sets of instances.

## Load Balancer Serving Requests in Private Subnets
A Load Balancer can serve requests in both **public (internet-facing)** and **private (internal-facing)** environments.

### **Internet-Facing Load Balancer**
- This type of load balancer has a **public IP address**.
- It routes incoming traffic from the internet to instances in public or private subnets.
- Example: A website with an ALB that serves users over the internet using an ACM SSL certificate.

### **Internal Load Balancer**
- This load balancer does **not have a public IP** and is accessible only within the VPC.
- It is used for **intranet applications** where traffic must remain private.
- Example: A company's HR portal that is only accessible within the corporate network.

## Listeners and Their Use Case
A **listener** is a process that checks for incoming connection requests using a specified **protocol and port**.
- Every load balancer **must have at least one listener** to accept traffic.
- A listener forwards requests to target groups based on defined **rules**.
- Example: An ALB with a listener on port 443 (HTTPS) that routes traffic to backend web servers.

## Why Load Balancers Perform Health Checks
Health checks ensure that traffic is sent only to **healthy instances**. The load balancer continuously monitors the targets and determines their status.

### **How Health Checks Work**
- The load balancer sends requests (health check probes) to each target at **regular intervals**.
- If a target **fails** the health check multiple times, it is marked as **unhealthy**, and traffic is no longer sent to it.
- If the instance becomes healthy again, it is re-added to the active rotation.

### **Health Check Parameters**
1. **Protocol**: The protocol used for health checks (e.g., HTTP, TCP, HTTPS).
2. **Port**: The port on which the health check is performed.
3. **Healthy Threshold**: Number of consecutive successful health checks before marking an instance as healthy.
4. **Unhealthy Threshold**: Number of consecutive failed health checks before marking an instance as unhealthy.
5. **Timeout**: The time to wait for a response from a target before considering the health check failed.
6. **Interval**: The time between two consecutive health check attempts.

### **Example Health Check Configuration**
- **Protocol**: HTTP
- **Port**: 80
- **Healthy Threshold**: 3
- **Unhealthy Threshold**: 2
- **Timeout**: 5 seconds
- **Interval**: 30 seconds

### **What Happens When a Health Check Fails?**
- The load balancer stops sending traffic to the unhealthy instance.
- If all instances in a target group fail, requests may **fail completely** unless a backup target group is configured.
- Once the instance recovers and passes the health check, it is **reintroduced** into the load balancing pool.

## Conclusion
AWS Load Balancers are essential for distributing traffic efficiently across multiple backend servers. Understanding key concepts such as **load balancer types, target groups, listeners, health checks, and private/public load balancing** helps in designing robust and scalable applications in AWS.

---
---
---
