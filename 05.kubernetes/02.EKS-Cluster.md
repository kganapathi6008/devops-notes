# EKS Cluster and Node Group Configuration with Pod Scheduling Limitations

## IAM Role Creation

### 1. EKS Cluster Role (`eks_cluster_role`)

* Go to IAM → Create Role
* **Trusted entity type**: AWS Service
* **Use case**: EKS → EKS - Cluster
* **Permissions policy**: Attach the policy `AmazonEKSClusterPolicy`
* **Name** the role `eks_cluster_role`

### 2. EKS Node Role (`eks_node_role`)

* Go to IAM → Create Role
* **Trusted entity type**: AWS Service
* **Use case**: EC2
* **Permissions policies**: Attach the following:

  * `AmazonEKSWorkerNodePolicy`
  * `AmazonEC2ContainerRegistryReadOnly`
  * `AmazonEKS_CNI_Policy`
* **Name** the role `eks_node_role`

---

## EKS Cluster Configuration

### Step 1: Cluster

* **Name**: eks-dev-env
* **Kubernetes version**: 1.32
* **EKS Auto Mode**: Disabled
* **Upgrade policy**: Standard
* **Cluster IAM role**: `arn:aws:iam::111111111111:role/eks_cluster_role`
* **Kubernetes cluster administrator access**: Allow cluster administrator access
* **Authentication mode**: EKS API and ConfigMap

### Step 2: Networking

* **VPC**: Default VPC
* **Cluster IP address family**: IPv4
* **Subnets**: All subnets selected

**Cluster endpoint access**:

* **API server endpoint access**: Public
* **Public access source allowlist**: `0.0.0.0/0`

### Step 3: Observability

* **Control plane logs**:

  * API server: Off
  * Audit: Off
  * Authenticator: Off
  * Controller manager: Off
  * Scheduler: Off

### Step 4: Add-ons

* coredns
* kube-proxy
* vpc-cni

---

## EKS Node Group Configuration

### Step 1: Node group

* **Name**: eks-dev-env-ng
* **Node IAM role**: `arn:aws:iam::111111111111:role/eks_node_role`

### Step 2: Compute and Scaling Configuration

* **Capacity type**: On-Demand
* **AMI type**: Amazon Linux 2023 (x86\_64) Standard (AL2023\_x86\_64\_STANDARD)
* **Instance types**: `t3.medium`
* **Disk size**: 20 GiB

**Scaling configuration**:

* **Desired size**: 1 node
* **Minimum size**: 1 node
* **Maximum size**: 3 nodes

**Update configuration**:

* **Maximum unavailable**: 1 node
* **Update strategy**: Default

### Step 3: Networking

* **Subnets**: All subnets of default VPC selected
* **Configure remote access to nodes**: Off

---

## Pod Scheduling Limitation Based on Instance Type

### Instance: t2.micro

* **vCPU**: 1
* **Memory**: 1 GiB
* **Max ENIs**: 2
* **Max IPs per ENI**: 2
* **Total Max Pods**: 4

### Instance: t3.medium

* **vCPU**: 2
* **Memory**: 4 GiB
* **Max ENIs**: 3
* **Max IPs per ENI**: 6
* **Total Max Pods**: 18

### Explanation:

* When a `t2.micro` instance is used in the EKS node group, it supports only 4 IP addresses (pods).
* Some pods are automatically scheduled in the `kube-system` namespace:

  ```bash
  kubectl get pods -n kube-system -o wide
  ```
* Example output:

  * `aws-node`
  * `coredns` x2
  * `kube-proxy`
* These consume the available IPs.

### Result:

* If user deploys an additional application (e.g., `nginx`), it stays in `Pending` state:

  ```bash
  kubectl get pods
  NAME                     READY   STATUS    RESTARTS   AGE
  nginx-xxxxx              0/1     Pending   0          19m
  ```
* This happens because no additional IPs are available on the node.

---

## Confirm Max Pods Per Node Using CLI

Run the following command to check how many pods a node can host:

```bash
kubectl get node <node-name> -o json | jq '.status.allocatable.pods'
```

Example outputs:

```bash
$ kubectl get node ip-172-31-26-39.eu-west-2.compute.internal -o json | jq '.status.allocatable.pods'
"4"

$ kubectl get node ip-172-31-23-118.eu-west-2.compute.internal -o json | jq '.status.allocatable.pods'
"17"
```

This value confirms how many pods (IP addresses) the instance can support.

---

## Conclusion

* Choose instance types carefully based on expected pod count.
* t2.micro is suitable only for testing/light workloads due to low pod capacity.
* t3.medium offers better pod density and is suitable for small production or dev environments.
* You can also increase max pods per node by customizing ENI configs or using custom networking, but it requires advanced setup.
